{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train a model"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "``graph-pes-train`` provides a unified interface to train any :class:`~graph_pes.core.GraphPESModel`, including those packaged within :doc:`graph_pes.models <../models/root>` and those defined by you, the user.\n",
                "\n",
                ".. seealso::\n",
                "\n",
                "    For more information on the ``graph-pes-train`` command, and the plethora of options available for specification in your ``config.yaml`` see the :ref:`CLI reference <cli-reference>`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully installed graph-pes-0.0.1\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "pip install graph-pes | tail -n 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now should have access to the ``graph-pes-train`` command. We can check this by running:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "usage: graph-pes-train [-h] [--config CONFIG] [overrides ...]\n",
                        "\n",
                        "Train a GraphPES model from a configuration file using PyTorch Lightning.\n",
                        "\n",
                        "positional arguments:\n",
                        "  overrides        Config overrides in the form nested^key=value, separated by\n",
                        "                   spaces, e.g. fitting^loader_kwargs^batch_size=32.\n",
                        "\n",
                        "options:\n",
                        "  -h, --help       show this help message and exit\n",
                        "  --config CONFIG  Path to the configuration file. This argument can be used\n",
                        "                   multiple times, with later files taking precedence over\n",
                        "                   earlier ones in the case of conflicts. If no config files\n",
                        "                   are provided, the script will auto-generate.\n",
                        "\n",
                        "Copyright 2023-24, John Gardner\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "graph-pes-train -h"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "Great - now lets train a model. To do this, we have specified the following in our ``quickstart-config.yaml`` file:\n",
                "\n",
                "* the model architecture to instantiate and train (here :class:`~graph_pes.models.PaiNN`) \n",
                "* the data to train on (here the `QM7 <https://jla-gardner.github.io/load-atoms/datasets/QM7.html>`_ dataset downloaded internally using `load-atoms <https://jla-gardner.github.io/load-atoms/>`_) \n",
                "* the loss function to use (here a simple :class:`~graph_pes.training.loss.PerAtomEnergyLoss`) \n",
                "* and various other training hyperparameters (e.g. the learning rate, batch size, etc.)\n",
                "\n",
                ".. literalinclude:: quickstart-config.yaml\n",
                "    :language: yaml\n",
                "    :caption: quickstart-config.yaml\n",
                "    :linenos:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Set logging level to INFO\n",
                        "[graph-pes INFO]: Started training at 2024-09-16 17:02:04.007\n",
                        "[graph-pes INFO]: Output directory: graph-pes-results/quickstart-run\n",
                        "[graph-pes INFO]: \n",
                        "Logging using WandbLogger(\n",
                        "  project=\"graph-pes\",\n",
                        "  id=\"quickstart-run\",\n",
                        "  save_dir=\"graph-pes-results\"\n",
                        ")\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "wandb: Currently logged in as: jla-gardner. Use `wandb login --relogin` to force relogin\n",
                        "wandb: wandb version 0.18.0 is available!  To upgrade, please run:\n",
                        "wandb:  $ pip install wandb --upgrade\n",
                        "wandb: Tracking run with wandb version 0.17.1\n",
                        "wandb: Run data is saved locally in graph-pes-results/wandb/run-20240916_170205-quickstart-run\n",
                        "wandb: Run `wandb offline` to turn off syncing.\n",
                        "wandb: Resuming run trial-run\n",
                        "wandb: â­ï¸ View project at https://wandb.ai/jla-gardner/graph-pes\n",
                        "wandb: ğŸš€ View run at https://wandb.ai/jla-gardner/graph-pes/runs/quickstart-run\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Logging to graph-pes-results/quickstart-run/logs/rank-0.log\n",
                        "[graph-pes INFO]: \n",
                        "model:\n",
                        "   graph_pes.models.PaiNN:\n",
                        "      layers: 3\n",
                        "      cutoff: 3.0\n",
                        "data:\n",
                        "   graph_pes.data.load_atoms_dataset:\n",
                        "      id: QM7\n",
                        "      cutoff: 3.0\n",
                        "      n_train: 1000\n",
                        "      n_valid: 100\n",
                        "loss: graph_pes.training.loss.PerAtomEnergyLoss()\n",
                        "fitting:\n",
                        "   pre_fit_model: true\n",
                        "   max_n_pre_fit: 5000\n",
                        "   early_stopping_patience: null\n",
                        "   trainer_kwargs:\n",
                        "      max_epochs: 25\n",
                        "      accelerator: auto\n",
                        "      enable_model_summary: false\n",
                        "   loader_kwargs:\n",
                        "      num_workers: 0\n",
                        "      persistent_workers: false\n",
                        "      batch_size: 16\n",
                        "      pin_memory: false\n",
                        "   optimizer:\n",
                        "      graph_pes.training.opt.Optimizer:\n",
                        "         name: AdamW\n",
                        "         lr: 0.01\n",
                        "   scheduler: null\n",
                        "   swa: null\n",
                        "general:\n",
                        "   seed: 42\n",
                        "   root_dir: graph-pes-results\n",
                        "   run_id: quickstart-run\n",
                        "   log_level: INFO\n",
                        "   progress: logged\n",
                        "wandb:\n",
                        "   project: graph-pes\n",
                        "\n",
                        "[graph-pes INFO]: \n",
                        "FittingData(\n",
                        "  train=ASEDataset(1,000, labels=['energy']),\n",
                        "  valid=ASEDataset(100, labels=['energy'])\n",
                        ")\n",
                        "\n",
                        "[graph-pes INFO]: Optimizer(name=\"AdamW\", lr=0.01)\n",
                        "[graph-pes INFO]: No LR scheduler.\n",
                        "[graph-pes INFO]: \n",
                        "TotalLoss:\n",
                        "    (weight) : (loss)\n",
                        "         1.0 : PerAtomEnergyLoss(\"energy\", metric=MAE())\n",
                        "\n",
                        "[graph-pes INFO]: Starting training on rank 0.\n",
                        "[graph-pes INFO]: Preparing data\n",
                        "[graph-pes INFO]: Setting up datasets\n",
                        "[graph-pes INFO]: Pre-fitting the model on 1,000 samples\n",
                        "[graph-pes INFO]: \n",
                        "Model:\n",
                        "PaiNN(\n",
                        "  (z_embedding): PerElementEmbedding(\n",
                        "    dim=32,\n",
                        "    elements=['H', 'C', 'N', 'O', 'S']\n",
                        "  )\n",
                        "  (interactions): UniformModuleList(\n",
                        "    (0-2): 3 x Interaction(\n",
                        "      (filter_generator): HaddamardProduct(\n",
                        "        (components): ModuleList(\n",
                        "          (0): Sequential(\n",
                        "            (0): Bessel(n_features=20, cutoff=3.0, trainable=True)\n",
                        "            (1): Linear(in_features=20, out_features=96, bias=True)\n",
                        "          )\n",
                        "          (1): PolynomialEnvelope(cutoff=3.0, p=6)\n",
                        "        )\n",
                        "      )\n",
                        "      (Phi): MLP(32 â†’ 32 â†’ 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (updates): UniformModuleList(\n",
                        "    (0-2): 3 x Update(\n",
                        "      (U): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (V): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (mlp): MLP(64 â†’ 32 â†’ 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (read_out): MLP(32 â†’ 32 â†’ 1, activation=SiLU())\n",
                        ")\n",
                        "\n",
                        "[graph-pes INFO]: Number of learnable params : 41,922\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   epoch   valid/loss/total   valid/loss/per_atom_energy_mae_component   timer/its_per_s/train   timer/its_per_s/valid\n",
                        "       0            0.14216                                    0.14216                83.33334               207.14285\n",
                        "       1            0.14075                                    0.14075                90.90909               221.42857\n",
                        "       2            0.05074                                    0.05074                90.90909               214.28572\n",
                        "       3            0.03484                                    0.03484               100.00000               214.28572\n",
                        "       4            0.05504                                    0.05504                90.90909               214.28572\n",
                        "       5            0.07713                                    0.07713                83.33334               207.14285\n",
                        "       6            0.16388                                    0.16388                83.33334               221.42857\n",
                        "       7            0.07709                                    0.07709                90.90909               214.28572\n",
                        "       8            0.08028                                    0.08028                90.90909               221.42857\n",
                        "       9            0.05346                                    0.05346                90.90909               214.28572\n",
                        "      10            0.03754                                    0.03754                90.90909               191.83675\n",
                        "      11            0.02777                                    0.02777               100.00000               221.42857\n",
                        "      12            0.05072                                    0.05072               100.00000               221.42857\n",
                        "      13            0.13440                                    0.13440                83.33334               214.28572\n",
                        "      14            0.04300                                    0.04300                90.90909               221.42857\n",
                        "      15            0.07749                                    0.07749               100.00000               221.42857\n",
                        "      16            0.09298                                    0.09298                90.90909               214.28572\n",
                        "      17            0.03013                                    0.03013               100.00000               221.42857\n",
                        "      18            0.08891                                    0.08891                90.90909               221.42857\n",
                        "      19            0.07983                                    0.07983                90.90909               221.42857\n",
                        "      20            0.04339                                    0.04339                90.90909               228.57143\n",
                        "      21            0.13229                                    0.13229               100.00000               214.28572\n",
                        "      22            0.05224                                    0.05224                90.90909               228.57143\n",
                        "      23            0.07204                                    0.07204                90.90909               221.42857\n",
                        "      24            0.06264                                    0.06264                90.90909               221.42857\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Loading best weights from \"graph-pes-results/quickstart-run/checkpoints/best.ckpt\"\n",
                        "[graph-pes INFO]: Training complete.\n",
                        "[graph-pes INFO]: Model saved to graph-pes-results/quickstart-run/model.pt\n",
                        "[graph-pes INFO]: Deploying model for use with LAMMPS to graph-pes-results/quickstart-run/lammps_model.pt\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: \\ 0.013 MB of 0.013 MB uploaded\n",
                        "wandb: Run history:\n",
                        "wandb:                                    epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
                        "wandb:                           lr-AdamW/model â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
                        "wandb:                   n_learnable_parameters â–\n",
                        "wandb:                             n_parameters â–\n",
                        "wandb:                    timer/its_per_s/train â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–ˆâ–ˆâ–†â–†â–ˆâ–†â–†â–ˆâ–†â–„â–†â–„â–„â–†â–†â–â–†\n",
                        "wandb:                    timer/its_per_s/valid â–„â–‡â–…â–…â–…â–„â–‡â–…â–‡â–…â–â–‡â–‡â–…â–‡â–‡â–…â–‡â–‡â–‡â–ˆâ–…â–ˆâ–‡â–‡\n",
                        "wandb:             timer/step_duration_ms/train â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–…â–ƒâ–…â–…â–ƒâ–ƒâ–ˆâ–ƒ\n",
                        "wandb:             timer/step_duration_ms/valid â–…â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚â–‚\n",
                        "wandb: train/loss/per_atom_energy_mae_component â–†â–ˆâ–‚â–â–‚â–ƒâ–‚â–‚â–„â–â–â–â–â–‚â–‚â–â–„â–â–â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚\n",
                        "wandb:                         train/loss/total â–†â–ˆâ–‚â–â–‚â–ƒâ–‚â–‚â–„â–â–â–â–â–‚â–‚â–â–„â–â–â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚\n",
                        "wandb:        train/metrics/per_atom_energy_mae â–†â–ˆâ–‚â–â–‚â–ƒâ–‚â–‚â–„â–â–â–â–â–‚â–‚â–â–„â–â–â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚\n",
                        "wandb:                      trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
                        "wandb: valid/loss/per_atom_energy_mae_component â–‡â–‡â–‚â–â–‚â–„â–ˆâ–„â–„â–‚â–‚â–â–‚â–†â–‚â–„â–„â–â–„â–„â–‚â–†â–‚â–ƒâ–ƒ\n",
                        "wandb:                         valid/loss/total â–‡â–‡â–‚â–â–‚â–„â–ˆâ–„â–„â–‚â–‚â–â–‚â–†â–‚â–„â–„â–â–„â–„â–‚â–†â–‚â–ƒâ–ƒ\n",
                        "wandb:        valid/metrics/per_atom_energy_mae â–‡â–‡â–‚â–â–‚â–„â–ˆâ–„â–„â–‚â–‚â–â–‚â–†â–‚â–„â–„â–â–„â–„â–‚â–†â–‚â–ƒâ–ƒ\n",
                        "wandb: \n",
                        "wandb: Run summary:\n",
                        "wandb:                                    epoch 24\n",
                        "wandb:                           lr-AdamW/model 0.01\n",
                        "wandb:                   n_learnable_parameters 41922\n",
                        "wandb:                             n_parameters 41922\n",
                        "wandb:                    timer/its_per_s/train 90.90909\n",
                        "wandb:                    timer/its_per_s/valid 221.42857\n",
                        "wandb:             timer/step_duration_ms/train 11.0\n",
                        "wandb:             timer/step_duration_ms/valid 4.57143\n",
                        "wandb: train/loss/per_atom_energy_mae_component 0.06708\n",
                        "wandb:                         train/loss/total 0.06708\n",
                        "wandb:        train/metrics/per_atom_energy_mae 0.06708\n",
                        "wandb:                      trainer/global_step 1574\n",
                        "wandb: valid/loss/per_atom_energy_mae_component 0.06264\n",
                        "wandb:                         valid/loss/total 0.06264\n",
                        "wandb:        valid/metrics/per_atom_energy_mae 0.06264\n",
                        "wandb: \n",
                        "wandb: ğŸš€ View run trial-run at: https://wandb.ai/jla-gardner/graph-pes/runs/quickstart-run\n",
                        "wandb: â­ï¸ View project at: https://wandb.ai/jla-gardner/graph-pes\n",
                        "wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
                        "wandb: Find logs at: graph-pes-results/wandb/run-20240916_170205-quickstart-run/logs\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "export LOAD_ATOMS_VERBOSE=0  # disable load-atoms progress bars\n",
                "graph-pes-train --config quickstart-config.yaml"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "trash",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
